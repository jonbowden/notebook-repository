{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e61679d4",
   "metadata": {},
   "source": [
    "# Module 8 Assessment — Agents & Automation (Student Version)\n",
    "\n",
    "**Auto-graded | Code-heavy (≈80%) | Tough by design**\n",
    "\n",
    "You will implement a **bounded triage agent** with:\n",
    "- strict action schema\n",
    "- deterministic tool execution\n",
    "- guardrails and refusal behaviour\n",
    "- explicit termination (no infinite loops)\n",
    "- logging for auditability\n",
    "\n",
    "This is not the capstone — but it tests the skills you will need for it.\n",
    "\n",
    "---\n",
    "\n",
    "## Rules\n",
    "- Do not rename required variables or functions.\n",
    "- Do not add new actions beyond the allowed set.\n",
    "- Do not allow unbounded loops.\n",
    "- Keep agent behaviour auditable and deterministic outside the LLM decision step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fa8226",
   "metadata": {},
   "source": [
    "## Setup (DO NOT MODIFY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5531aa2",
   "metadata": {},
   "outputs": [],
   "source": "import json\nimport time\nfrom typing import List, Dict, Any, Optional, Tuple\n\n# Install the mock toolkit used throughout Module 8\n!pip install -q git+https://github.com/jonbowden/notebook-repository.git#subdirectory=packages/codevision-mock-toolkit\n\nfrom mock_toolkit import (\n    MockLLMClient, ALLOWED_ACTIONS, REFUSAL_TEXT,\n    classify_only, retrieve_and_answer, refuse,\n)\n\nllm_client = MockLLMClient()\n\nprint(\"Setup complete — using MockLLMClient from mock_toolkit.\")\nprint(f\"Allowed actions: {sorted(ALLOWED_ACTIONS)}\")\nprint(f\"Refusal text: {REFUSAL_TEXT}\")"
  },
  {
   "cell_type": "markdown",
   "id": "bf49b161",
   "metadata": {},
   "source": "## Task 1 — Implement `decide_action` (20 pts)\n\nImplement:\n\n```python\ndef decide_action(llm_client, user_input: str) -> str:\n    ...\n```\n\nRequirements:\n- Build a prompt that includes the user input (use the prefix `User input: ` so the mock can extract it)\n- Call `llm_client.chat(prompt)` which returns JSON like `{\"action\": \"retrieve_and_answer\"}`\n- Parse JSON safely\n- If parsing fails or action not in `ALLOWED_ACTIONS`, return `\"refuse\"`\n- Return only one of the allowed actions"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8e2d5a",
   "metadata": {},
   "outputs": [],
   "source": "def decide_action(llm_client, user_input: str) -> str:\n    # TODO\n    return None"
  },
  {
   "cell_type": "markdown",
   "id": "c04e6204",
   "metadata": {},
   "source": "## Task 2 — Implement `triage_agent` (20 pts)\n\nImplement:\n\n```python\ndef triage_agent(user_input: str) -> str:\n    ...\n```\n\nRequirements:\n- Use `decide_action(llm_client, user_input)`\n- If action is:\n  - `retrieve_and_answer` → call `retrieve_and_answer(user_input)`\n  - `classify_only` → call `classify_only(user_input)`\n  - `refuse` → call `refuse()`\n- Do NOT call any other tools\n- Must return a string"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f03db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triage_agent(user_input: str) -> str:\n",
    "    # TODO\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011a45fb",
   "metadata": {},
   "source": "## Task 3 — Implement `triage_agent_with_guardrails` (20 pts)\n\nWe simulate confidence by a simple heuristic:\n- If the input contains \"maybe\" or \"not sure\" → treat as low confidence\n- If the input is too short (< 8 chars) → treat as low confidence\n\nImplement:\n\n```python\ndef triage_agent_with_guardrails(user_input: str) -> str:\n    ...\n```\n\nRequirements:\n- If low-confidence: return `REFUSAL_TEXT`\n- Otherwise: behave like `triage_agent`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843a84d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triage_agent_with_guardrails(user_input: str) -> str:\n",
    "    # TODO\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c624ddd8",
   "metadata": {},
   "source": "## Task 4 — Implement `agent_loop` + audit log (20 pts)\n\nImplement:\n\n```python\ndef agent_loop(user_input: str, max_steps: int = 2) -> Tuple[str, List[dict]]:\n    ...\n```\n\nRequirements:\n- Must never exceed `max_steps` iterations\n- On each step, record a log entry dict with keys:\n  - `step` (int)\n  - `input` (str)\n  - `action` (str)\n  - `output` (str)\n- Must call `triage_agent_with_guardrails`\n- Return `(final_output, logs)`\n\nThis tests control, termination, and auditability."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81870564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_loop(user_input: str, max_steps: int = 2):\n",
    "    # TODO\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49629d3a",
   "metadata": {},
   "source": [
    "## Task 5 — Written Explanation (20 pts)\n",
    "\n",
    "Write 6–10 sentences explaining:\n",
    "- why actions must be bounded\n",
    "- why refusal is a success case\n",
    "- why termination conditions are mandatory\n",
    "- how logging supports auditability\n",
    "\n",
    "Store the text in `explanation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b86672",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = \"\"\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fbc52f",
   "metadata": {},
   "source": "---\n## Quick self-test (optional)\nThese should run after you complete the tasks:\n\n```python\nprint(triage_agent(\"Why did the central bank raise rates?\"))\nprint(triage_agent(\"Classify this sentence about loans\"))\nprint(triage_agent(\"Should we approve a loan for customer X?\"))\nprint(agent_loop(\"Why did the central bank raise rates?\", max_steps=2))\n```\n\nExpected outputs:\n- Query 1 → starts with `\"Based on retrieved documents:\"`\n- Query 2 → starts with `\"Topic:\"`\n- Query 3 → equals `REFUSAL_TEXT`"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}