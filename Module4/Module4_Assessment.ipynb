{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d458d54",
   "metadata": {},
   "source": [
    "# Module 4 Assessment — ML & DL Foundations\n",
    "\n",
    "This assessment tests both your **conceptual understanding** (written tasks) and **practical skills** (coding tasks).\n",
    "\n",
    "## Assessment Structure\n",
    "- **3 Written Tasks** (55 points): Explain concepts in your own words\n",
    "- **3 Coding Tasks** (45 points): Implement ML fundamentals in Python\n",
    "\n",
    "## Instructions\n",
    "- **Written tasks**: Fill in the string variables with full sentences\n",
    "- **Coding tasks**: Complete the functions with the exact signatures shown\n",
    "- Do **not** rename variables or functions\n",
    "- Ensure the notebook runs top-to-bottom without errors\n",
    "- You may use the module content for reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3237a7",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 1 — Concept Mapping (15 points) [Written]\n",
    "\n",
    "**Prompt:** Explain the relationship between **AI**, **ML**, **DL**, and **LLMs**.\n",
    "\n",
    "Include:\n",
    "- The subset chain (AI → ML → DL)\n",
    "- Where LLMs sit (DL + Generative AI)\n",
    "- One sentence on why this matters in enterprise settings\n",
    "\n",
    "Write **5–8 sentences**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98de0d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_mapping = \"\"\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "task2_md",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 2 — Loss Calculation (15 points) [Coding]\n",
    "\n",
    "**Implement a function that calculates the Mean Squared Error (MSE) loss.**\n",
    "\n",
    "MSE = (1/n) × Σ(predicted - actual)²\n",
    "\n",
    "```python\n",
    "def calculate_mse(predictions, actuals):\n",
    "    \"\"\"\n",
    "    Calculate Mean Squared Error between predictions and actual values.\n",
    "    \n",
    "    Args:\n",
    "        predictions: list of predicted values\n",
    "        actuals: list of actual values (same length as predictions)\n",
    "    \n",
    "    Returns:\n",
    "        float: the mean squared error\n",
    "    \"\"\"\n",
    "```\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "calculate_mse([10, 20, 30], [12, 18, 33])  # Returns 6.0\n",
    "# Because: ((10-12)² + (20-18)² + (30-33)²) / 3 = (4 + 4 + 9) / 3 = 17/3 ≈ 5.67\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task2_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mse(predictions, actuals):\n",
    "    \"\"\"\n",
    "    Calculate Mean Squared Error between predictions and actual values.\n",
    "    \n",
    "    Args:\n",
    "        predictions: list of predicted values\n",
    "        actuals: list of actual values (same length as predictions)\n",
    "    \n",
    "    Returns:\n",
    "        float: the mean squared error\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5df768",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 3 — How Learning Works (20 points) [Written]\n",
    "\n",
    "**Prompt:** Explain how a neural network learns during training.\n",
    "\n",
    "Include:\n",
    "- Loss function (error signal)\n",
    "- Gradient descent (minimising loss)\n",
    "- Backpropagation (error flowing backward)\n",
    "- Learning rate (step size; too large → instability)\n",
    "- Convergence (what it means and what it doesn't guarantee)\n",
    "\n",
    "*You may find it helpful to think in terms of the \"hiker in fog\" analogy from the module.*\n",
    "\n",
    "Write **7–12 sentences**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead8ae7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_mechanics = \"\"\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "task4_md",
   "metadata": {},
   "source": "---\n## Task 4 — Gradient Descent Step (15 points) [Coding]\n\n**Implement a single gradient descent update step for a simple linear model.**\n\nFor a model `prediction = weight × input`, the gradient of MSE loss with respect to the weight is:\n\n`gradient = (2/n) × Σ((prediction - actual) × input)`\n\nThe weight update is: `new_weight = old_weight - learning_rate × gradient`\n\n```python\ndef gradient_descent_step(weight, inputs, actuals, learning_rate):\n    \"\"\"\n    Perform one gradient descent step for a simple linear model (no bias).\n    \n    Args:\n        weight: current weight value (float)\n        inputs: list of input values\n        actuals: list of actual target values\n        learning_rate: step size (float)\n    \n    Returns:\n        float: the updated weight after one gradient descent step\n    \"\"\"\n```\n\n**Example:**\n```python\ngradient_descent_step(3.0, [1, 2], [2, 4], 0.1)  # Returns 2.5\n# The true relationship is: actual = 2 × input (so optimal weight = 2)\n# Current predictions: [3×1, 3×2] = [3, 6]\n# Errors (pred - actual): [3-2, 6-4] = [1, 2]\n# Gradient = (2/2) × (1×1 + 2×2) = 1 × 5 = 5\n# New weight = 3 - 0.1 × 5 = 2.5 (moved closer to optimal!)\n```"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task4_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_step(weight, inputs, actuals, learning_rate):\n",
    "    \"\"\"\n",
    "    Perform one gradient descent step for a simple linear model (no bias).\n",
    "    \n",
    "    Args:\n",
    "        weight: current weight value (float)\n",
    "        inputs: list of input values\n",
    "        actuals: list of actual target values\n",
    "        learning_rate: step size (float)\n",
    "    \n",
    "    Returns:\n",
    "        float: the updated weight after one gradient descent step\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "task5_md",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 5 — Simple Neuron (15 points) [Coding]\n",
    "\n",
    "**Implement a single neuron with ReLU activation.**\n",
    "\n",
    "A neuron computes:\n",
    "1. Weighted sum: `z = Σ(input_i × weight_i) + bias`\n",
    "2. Activation: `output = ReLU(z) = max(0, z)`\n",
    "\n",
    "```python\n",
    "def simple_neuron(inputs, weights, bias):\n",
    "    \"\"\"\n",
    "    Compute the output of a single neuron with ReLU activation.\n",
    "    \n",
    "    Args:\n",
    "        inputs: list of input values\n",
    "        weights: list of weights (same length as inputs)\n",
    "        bias: bias term (float)\n",
    "    \n",
    "    Returns:\n",
    "        float: neuron output after ReLU activation\n",
    "    \"\"\"\n",
    "```\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "simple_neuron([1, 2], [0.5, -0.5], 0.1)  # Returns 0.1\n",
    "# Because: (1×0.5 + 2×(-0.5)) + 0.1 = 0.5 - 1 + 0.1 = -0.4 → ReLU(-0.4) = 0\n",
    "\n",
    "simple_neuron([1, 2], [0.5, 0.5], 0.1)   # Returns 1.6\n",
    "# Because: (1×0.5 + 2×0.5) + 0.1 = 1.5 + 0.1 = 1.6 → ReLU(1.6) = 1.6\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task5_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_neuron(inputs, weights, bias):\n",
    "    \"\"\"\n",
    "    Compute the output of a single neuron with ReLU activation.\n",
    "    \n",
    "    Args:\n",
    "        inputs: list of input values\n",
    "        weights: list of weights (same length as inputs)\n",
    "        bias: bias term (float)\n",
    "    \n",
    "    Returns:\n",
    "        float: neuron output after ReLU activation\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4a400a",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 6 — LLM Behaviour + Grounding (20 points) [Written]\n",
    "\n",
    "**Prompt:** Based on your understanding of ML/DL, explain why LLM hallucinations are expected and why grounding (RAG) helps.\n",
    "\n",
    "Include:\n",
    "- Hallucination as pattern completion / over-generalisation\n",
    "- Connection to training data and next-token prediction\n",
    "- Why enterprise settings require evidence and auditability\n",
    "- Grounding/retrieval/RAG as mitigation (evidence + context)\n",
    "\n",
    "Write **7–12 sentences**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a920a943",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_grounding_reflection = \"\"\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122fdd9c",
   "metadata": {},
   "source": "---\n## Submission\n\nBefore submitting:\n1. **Restart kernel** and **Run All Cells** to ensure everything works\n2. Verify all functions are defined and return correct types\n3. Verify all written responses are complete and in your own words\n4. Save the notebook\n\n### How to Download from Colab\n1. Go to **File → Download → Download .ipynb**\n2. The file will download to your computer\n3. **Do not rename the file** — keep it as `Module4_Assessment.ipynb`\n\n### Submit\nUpload your completed notebook via the [Module 4 Assessment Form](https://docs.google.com/forms/d/e/1FAIpQLSdtHWeARFyjS_Oqs_1H1BM0M1rJtdcfYDaOmejchvkebmWcEQ/viewform).\n\n### Submission Checklist\n- [ ] All written variables filled with thoughtful explanations **in your own words**\n- [ ] All coding functions implemented and working\n- [ ] Notebook runs top-to-bottom without errors\n- [ ] Downloaded as .ipynb (not edited in a text editor)\n- [ ] File not renamed"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}