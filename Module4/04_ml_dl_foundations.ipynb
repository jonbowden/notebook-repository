{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Content\n\nThis notebook explains **Machine Learning (ML)** and **Deep Learning (DL)** in a simple, intuitive way.\n\nYou do **not** need advanced math.  \nThe goal is to understand *ideas*, not formulas.\n\nðŸ“º **Watch first:** [Hiker in the Fog â€” ML Analogy Video](https://youtu.be/NJ7YGL2Ulx4?si=W67z71ZtPLmgVzeZ) (recommended)\n\n---\n\n## One Big Idea to Remember\n\n> **Machine learning means adjusting numbers to make predictions less wrong.**\n\n---\n\n## Companion Resources\n- [Hiker's Cheat Sheet](Module4_Hiker_CheatSheet.md) â€” Maps analogy terms to technical terms\n- [Knowledge Checks](Module4_Knowledge_Checks.md) â€” Test your understanding"
  },
  {
   "cell_type": "markdown",
   "id": "bdn7scfxcnu",
   "source": "## Part 0 â€” The AI Family Tree: AI â†’ ML â†’ DL â†’ LLMs\n\nBefore diving in, let's understand how these terms relate:\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  ARTIFICIAL INTELLIGENCE (AI)                               â”‚\nâ”‚  Any system that mimics human-like intelligence             â”‚\nâ”‚                                                             â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚\nâ”‚  â”‚  MACHINE LEARNING (ML)                              â”‚   â”‚\nâ”‚  â”‚  AI that learns patterns from data                  â”‚   â”‚\nâ”‚  â”‚                                                     â”‚   â”‚\nâ”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚\nâ”‚  â”‚  â”‚  DEEP LEARNING (DL)                         â”‚   â”‚   â”‚\nâ”‚  â”‚  â”‚  ML using neural networks with many layers  â”‚   â”‚   â”‚\nâ”‚  â”‚  â”‚                                             â”‚   â”‚   â”‚\nâ”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚   â”‚\nâ”‚  â”‚  â”‚  â”‚  LLMs (Large Language Models)       â”‚   â”‚   â”‚   â”‚\nâ”‚  â”‚  â”‚  â”‚  DL models trained on text          â”‚   â”‚   â”‚   â”‚\nâ”‚  â”‚  â”‚  â”‚  Examples: GPT, Claude, Llama       â”‚   â”‚   â”‚   â”‚\nâ”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚   â”‚\nâ”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n### Key Relationships\n\n| Term | What it is | Example |\n|------|-----------|---------|\n| **AI** | Broad field of intelligent systems | Chess engines, Siri, self-driving cars |\n| **ML** | Subset of AI that learns from data | Spam filters, recommendation systems |\n| **DL** | Subset of ML using neural networks | Image recognition, speech-to-text |\n| **LLMs** | DL models for language (Generative AI) | ChatGPT, Claude, code assistants |\n\n### Why This Matters in Enterprise\n\nIn banking and enterprise settings, understanding this hierarchy helps you:\n- **Choose the right tool**: Not every problem needs an LLM\n- **Understand limitations**: Each layer inherits limitations from the ones above\n- **Manage risk**: LLMs add language-specific risks (hallucinations) on top of ML risks (overfitting)\n- **Communicate clearly**: Executives often confuse these terms",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Part 1 â€” The Hiker in the Fog\n\nImagine a hiker standing on a mountain covered in thick fog.\n\n- The hiker cannot see far.\n- The hiker does not know where the lowest point is.\n- The hiker can only feel whether the ground goes up or down.\n\nThe hiker's goal is simple:\n\n> **Reach the lowest point.**\n\nThis is how machine learning works:\n- Start with wrong guesses\n- Make small changes\n- Slowly improve\n\n---\n\n> **What the model does NOT know**\n> - It does not know the global optimum\n> - It does not know whether a better solution exists elsewhere\n> - It only reacts to *local feedback* (loss and gradient)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "| Story | Meaning |\n|---|---|\n| Hiker | The model |\n| Height | How wrong the model is |\n| Fog | Not knowing the right answer |\n| Step | Small change to the model |\n| Lowest point | Best possible model |"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Part 2 â€” What Is a Model?\n\nA **model** is a rule that turns inputs into outputs.\n\nExample:\n- Input: hours studied\n- Output: exam score"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "def predict(hours, weight, bias):\n    return weight * hours + bias\n\nweight = 1.0\nbias = 0.0\n\nprint(\"Prediction for 5 hours of study:\", predict(5, weight, bias))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Part 3 â€” Weights\n\n**Weights** are numbers inside the model.\n\n- They control predictions\n- They start as guesses\n- Learning means changing them\n\nLet's see how different weights change predictions:"
  },
  {
   "cell_type": "code",
   "id": "dlw38rg47om",
   "source": "# Same input, different weights = different predictions\nhours = 5\n\n# Try different weights\nfor weight in [1.0, 5.0, 10.0, 15.0]:\n    prediction = weight * hours\n    print(f\"Weight = {weight:4.1f}  â†’  Prediction = {prediction:5.1f}\")\n\nprint(\"\\nThe RIGHT weight depends on the actual data!\")\nprint(\"If students who study 5 hours score ~75, weight â‰ˆ 15 is best.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Part 4 â€” Loss\n\n**Loss** tells us how wrong a prediction is.\n\n- Big loss = very wrong\n- Small loss = almost right\n\nThe most common loss is **squared error**: (predicted - actual)Â²"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# Calculate loss for different predictions\nactual_score = 80\n\nprint(\"If actual score is 80:\")\nprint(\"-\" * 40)\n\nfor predicted in [60, 70, 75, 80, 85]:\n    loss = (predicted - actual_score) ** 2\n    print(f\"Predicted: {predicted}  â†’  Loss: {loss:4d}  {'â† Perfect!' if loss == 0 else ''}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Part 5 â€” Learning by Small Steps\n\nThe model changes its weights a little at a time.\n\nIf the loss gets smaller, the change was good.\nIf the loss gets bigger, try a different direction.\n\n*If you've watched the \"Hiker in the Fog\" video for this module, this is exactly what's happening: the model can't see the best solution, only the slope right under its feet.*"
  },
  {
   "cell_type": "code",
   "id": "3cwcify8f7c",
   "source": "# Gradient Descent: Finding the best weight step by step\n# Goal: predict exam scores from hours studied\n\n# Our \"training data\" - one student\nactual_hours = 5\nactual_score = 75\n\n# Start with a wrong guess\nweight = 1.0\nlearning_rate = 0.01  # Small steps! (0.1 would overshoot badly)\n\nprint(\"Gradient Descent in Action\")\nprint(\"=\" * 60)\nprint(f\"Goal: Find weight so that {actual_hours} hours â†’ {actual_score} points\")\nprint(f\"Perfect weight would be: {actual_score/actual_hours} (since {actual_score}/{actual_hours} = {actual_score/actual_hours})\")\nprint(f\"Starting weight: {weight} (way too low!)\")\nprint()\n\nfor step in range(8):\n    # 1. Make prediction with current weight\n    prediction = weight * actual_hours\n    \n    # 2. Calculate loss (how wrong are we?)\n    loss = (prediction - actual_score) ** 2\n    \n    # 3. Calculate gradient (which direction to go, and how steep)\n    #    Negative gradient means we need to INCREASE the weight\n    gradient = 2 * (prediction - actual_score) * actual_hours\n    \n    # 4. Update weight (take a small step in the right direction)\n    old_weight = weight\n    weight = weight - learning_rate * gradient\n    \n    direction = \"â†‘\" if weight > old_weight else \"â†“\"\n    print(f\"Step {step}: pred={prediction:5.1f}, loss={loss:8.1f}, weight {old_weight:.2f}â†’{weight:.2f} {direction}\")\n\nprint()\nprint(f\"Final weight: {weight:.2f} (target was {actual_score/actual_hours})\")\nprint(f\"Final prediction: {weight * actual_hours:.1f} (target was {actual_score})\")\nprint(\"âœ“ Loss decreased at every step - the model improved!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "zri0u71jgcj",
   "source": "### Backpropagation: How Errors Flow Backward\n\nIn the example above, we had one weight. But real networks have **millions** of weights across many layers. How do we know which weights to change?\n\n**Backpropagation** (\"backward propagation of errors\"):\n\n1. **Forward pass**: Input flows through the network â†’ prediction\n2. **Calculate loss**: Compare prediction to actual answer\n3. **Backward pass**: Error signal flows backward through each layer\n4. **Update weights**: Each weight gets adjusted based on how much it contributed to the error\n\n```\nFORWARD PASS (make prediction):\nInput â†’ Layer 1 â†’ Layer 2 â†’ Layer 3 â†’ Prediction\n\nBACKWARD PASS (assign blame):\n          â† Layer 1 â† Layer 2 â† Layer 3 â† Loss\n          (how much did each layer contribute to the error?)\n```\n\n**Key insight**: Weights that contributed more to the error get changed more.\n\nThis is why frameworks like PyTorch are valuableâ€”they compute backpropagation automatically!",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "vf9uay9l4ce",
   "source": "### Convergence: When Training Stops Improving\n\n**Convergence** means the model has stopped improvingâ€”the loss has settled to a stable value.\n\nBut convergence has an important limitation:\n\n```\n                    Global Minimum\n                         â†“\nLoss                     â˜…\n  â”‚    â•±â•²               \n  â”‚   â•±  â•²      Local   \n  â”‚  â•±    â•²    Minimum  \n  â”‚ â•±      â•²     â†“      \n  â”‚â•±        â•²    â€¢      \n  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Weights\n```\n\n| Term | Meaning | Implication |\n|------|---------|-------------|\n| **Local minimum** | A low point with higher points on both sides | Model might get \"stuck\" here |\n| **Global minimum** | The absolute lowest point | What we ideally want |\n| **Convergence** | Loss stopped decreasing | Does NOT mean we found the best solution! |\n\n**Why this matters for enterprise**:\n- A \"converged\" model might still be suboptimal\n- Different random starting weights can lead to different final models\n- This is why ML teams train multiple models and compare them",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "l3lkrn03c7",
   "source": "## Part 6 â€” Training\n\nTraining means:\n1. Make a prediction (forward pass)\n2. Measure how wrong it is (loss)\n3. Calculate gradients (backward pass)\n4. Adjust weights\n5. Repeat\n\nOne full pass through all training data is called an **epoch**.\n\nMultiple epochs = multiple passes through the same data, refining the model each time.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Part 7 â€” Common Problems and Mitigations\n\n### Overfitting\n\nThe model **memorizes** the training data instead of learning general patterns.\n\n**Signs of overfitting:**\n- Training loss is very low\n- Validation/test loss is much higher\n- Model fails on new data it hasn't seen\n\n### Underfitting\n\nThe model is **too simple** and fails to capture the patterns in the data.\n\n**Signs of underfitting:**\n- Both training and test loss are high\n- Model makes poor predictions on everything\n\n### Mitigations\n\n| Problem | Mitigation | How it helps |\n|---------|------------|--------------|\n| **Overfitting** | More training data | Harder to memorize larger datasets |\n| | Regularization (L1/L2) | Penalizes large weights, forces simplicity |\n| | Dropout | Randomly ignores neurons during training |\n| | Early stopping | Stop training when validation loss stops improving |\n| | Data augmentation | Create variations of training data |\n| **Underfitting** | More complex model | Add more layers/neurons |\n| | Train longer | More epochs to learn patterns |\n| | Better features | Provide more relevant input data |\n| | Reduce regularization | Allow model more flexibility |\n\n### Why This Matters in Financial Models\n\nIn banking and finance, overfitting is particularly dangerous:\n- A model might appear to predict market movements perfectly on historical data\n- But fail completely when deployed on new, real-world data\n- This can lead to significant financial losses\n- Regulatory bodies (like the Fed, PRA) require model validation to detect overfitting"
  },
  {
   "cell_type": "code",
   "id": "0je9jrmgbdud",
   "source": "# Complete Training Loop with Multiple Data Points\n# Training data: hours studied â†’ exam scores\ntraining_data = [\n    (1, 20),   # 1 hour  â†’ 20 points\n    (2, 35),   # 2 hours â†’ 35 points\n    (3, 50),   # 3 hours â†’ 50 points\n    (5, 75),   # 5 hours â†’ 75 points\n    (7, 90),   # 7 hours â†’ 90 points\n]\n\n# Initialize weight\nweight = 0.0\nlearning_rate = 0.01\n\nprint(\"Training over 3 epochs (3 passes through all data)\")\nprint(\"=\" * 55)\n\nfor epoch in range(3):\n    total_loss = 0\n    \n    for hours, actual in training_data:\n        # Forward pass: make prediction\n        prediction = weight * hours\n        \n        # Calculate loss\n        loss = (prediction - actual) ** 2\n        total_loss += loss\n        \n        # Backward pass: calculate gradient and update\n        gradient = 2 * (prediction - actual) * hours\n        weight = weight - learning_rate * gradient\n    \n    avg_loss = total_loss / len(training_data)\n    print(f\"Epoch {epoch + 1}: avg_loss = {avg_loss:8.1f}, weight = {weight:.2f}\")\n\nprint(f\"\\nFinal model: score = {weight:.1f} Ã— hours\")\nprint(f\"Prediction for 4 hours: {weight * 4:.0f} points\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "v0m6bo2vuwe",
   "source": "import matplotlib.pyplot as plt\n\n# Demonstrate overfitting vs good fit\n# Training data (what the model sees)\ntrain_hours = [1, 2, 3, 5, 7]\ntrain_scores = [20, 35, 50, 75, 90]\n\n# Test data (new, unseen data)\ntest_hours = [4, 6]\ntest_scores = [62, 82]  # Actual scores\n\n# Good model: simple linear fit (generalizes well)\ngood_weight = 12.5\n\n# Overfit model: memorized exact training points with complex formula\n# (simulated - in reality this would be a high-degree polynomial)\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 4))\n\n# Plot 1: Good Fit\nax1 = axes[0]\nax1.scatter(train_hours, train_scores, color='blue', s=100, label='Training data', zorder=5)\nax1.scatter(test_hours, test_scores, color='green', s=100, marker='s', label='Test data (unseen)', zorder=5)\nx_line = range(0, 9)\ny_line = [good_weight * x for x in x_line]\nax1.plot(x_line, y_line, 'b-', linewidth=2, label=f'Model: {good_weight}Ã—hours')\nax1.set_xlabel('Hours Studied')\nax1.set_ylabel('Exam Score')\nax1.set_title('GOOD FIT\\n(Generalizes to new data)')\nax1.legend()\nax1.grid(True, alpha=0.3)\nax1.set_xlim(0, 8)\nax1.set_ylim(0, 100)\n\n# Plot 2: Overfitting\nax2 = axes[1]\nax2.scatter(train_hours, train_scores, color='blue', s=100, label='Training data', zorder=5)\nax2.scatter(test_hours, test_scores, color='green', s=100, marker='s', label='Test data (unseen)', zorder=5)\n# Wiggly line that hits all training points but misses test points\nax2.plot(train_hours, train_scores, 'r-', linewidth=2, label='Overfit model')\nax2.scatter([4], [45], color='red', s=100, marker='x', label='Bad prediction!', zorder=5)\nax2.set_xlabel('Hours Studied')\nax2.set_ylabel('Exam Score')\nax2.set_title('OVERFITTING\\n(Memorized training, fails on new data)')\nax2.legend()\nax2.grid(True, alpha=0.3)\nax2.set_xlim(0, 8)\nax2.set_ylim(0, 100)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"Key insight: Overfitting = perfect on training, poor on new data\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Part 8 â€” Deep Learning\n\nDeep Learning uses many simple models together.\n\nEach small part is called a **neuron**.\n\nTogether, they can learn complex patterns.\n\n### Neural Network Architecture: Layers\n\nA neural network organizes neurons into **layers**:\n\n```\nINPUT LAYER          HIDDEN LAYER(S)         OUTPUT LAYER\n    â—‹                    â—‹                       â—‹\n    â—‹  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º   â—‹   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º    \n    â—‹                    â—‹                       \n                         â—‹\n```\n\n| Layer | Purpose | Example |\n|-------|---------|---------|\n| **Input Layer** | Receives raw data | Pixel values, hours studied, sensor readings |\n| **Hidden Layer(s)** | Learns patterns | Combines inputs in useful ways |\n| **Output Layer** | Produces final answer | Classification, score prediction |\n\n**\"Deep\" Learning = Many Hidden Layers**\n\n- 1-2 hidden layers = \"shallow\" network\n- 10+ hidden layers = \"deep\" network\n- GPT-4 has ~120 layers!\n\n### A Single Neuron\n\nA neuron does three things:\n1. **Multiply** inputs by weights\n2. **Add** a bias\n3. **Apply** an activation function (adds non-linearity)"
  },
  {
   "cell_type": "code",
   "id": "7w2v0cajy66",
   "source": "import matplotlib.pyplot as plt\n\n# A single neuron with ReLU activation\ndef relu(x):\n    \"\"\"ReLU: if negative, output 0. Otherwise, output x.\"\"\"\n    return max(0, x)\n\ndef neuron(inputs, weights, bias):\n    \"\"\"A single neuron: weighted sum + bias + activation\"\"\"\n    # Step 1: weighted sum\n    weighted_sum = sum(i * w for i, w in zip(inputs, weights))\n    \n    # Step 2: add bias\n    with_bias = weighted_sum + bias\n    \n    # Step 3: apply activation (ReLU)\n    output = relu(with_bias)\n    \n    return output\n\n# Example: 2 inputs (like hours studied, hours slept)\ninputs = [5, 8]  # 5 hours studied, 8 hours slept\nweights = [10, 5]  # studying matters more than sleep\nbias = -20\n\nresult = neuron(inputs, weights, bias)\nprint(f\"Inputs: {inputs}\")\nprint(f\"Weights: {weights}\")\nprint(f\"Bias: {bias}\")\nprint(f\"Weighted sum: {inputs[0]}Ã—{weights[0]} + {inputs[1]}Ã—{weights[1]} = {sum(i*w for i,w in zip(inputs, weights))}\")\nprint(f\"With bias: {sum(i*w for i,w in zip(inputs, weights))} + {bias} = {sum(i*w for i,w in zip(inputs, weights)) + bias}\")\nprint(f\"After ReLU: {result}\")\n\n# Visualize ReLU\nprint(\"\\n--- ReLU Activation Function ---\")\nx_vals = list(range(-5, 6))\ny_vals = [relu(x) for x in x_vals]\n\nplt.figure(figsize=(8, 3))\nplt.plot(x_vals, y_vals, 'b-', linewidth=2)\nplt.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\nplt.axvline(x=0, color='gray', linestyle='--', alpha=0.5)\nplt.xlabel('Input')\nplt.ylabel('Output')\nplt.title('ReLU: Negative â†’ 0, Positive â†’ unchanged')\nplt.grid(True, alpha=0.3)\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Part 9 â€” Training vs Using a Model\n\n- **Training:** weights change\n- **Using the model:** weights stay the same"
  },
  {
   "cell_type": "code",
   "id": "1ury5zmx1gki",
   "source": "# Training vs Inference: The Two Phases\n\nclass SimpleModel:\n    def __init__(self):\n        self.weight = 1.0  # Start with a guess\n        \n    def predict(self, hours):\n        return self.weight * hours\n    \n    def train_step(self, hours, actual_score, learning_rate=0.01):\n        \"\"\"Training: weights CHANGE\"\"\"\n        prediction = self.predict(hours)\n        gradient = 2 * (prediction - actual_score) * hours\n        self.weight = self.weight - learning_rate * gradient\n        return prediction\n\n# Create model\nmodel = SimpleModel()\n\nprint(\"=\" * 50)\nprint(\"PHASE 1: TRAINING (weights change)\")\nprint(\"=\" * 50)\ntraining_examples = [(3, 45), (5, 75), (7, 105)]\n\nfor hours, score in training_examples:\n    old_weight = model.weight\n    pred = model.train_step(hours, score)\n    print(f\"Input: {hours}h â†’ Actual: {score}, Predicted: {pred:.0f}\")\n    print(f\"  Weight changed: {old_weight:.2f} â†’ {model.weight:.2f}\")\n\nprint()\nprint(\"=\" * 50)\nprint(\"PHASE 2: INFERENCE (weights frozen)\")\nprint(\"=\" * 50)\nprint(f\"Final trained weight: {model.weight:.2f}\")\nprint()\n\n# Now use the trained model (no more training)\nfor hours in [1, 4, 6, 10]:\n    prediction = model.predict(hours)\n    print(f\"Inference: {hours} hours â†’ predicted score: {prediction:.0f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "rdw5v6qtrm",
   "source": "## Part 10 â€” LLMs: How Language Models Work (and Why They Hallucinate)\n\nNow that you understand ML/DL fundamentals, let's see how they apply to **Large Language Models (LLMs)** like GPT and Claude.\n\n### How LLMs Are Trained\n\nLLMs learn through **self-supervised learning** on massive text datasets:\n\n1. **Training data**: Billions of documents from the internet, books, code\n2. **Task**: Predict the next word (token) given previous words\n3. **Process**: Same gradient descent we learnedâ€”adjust weights to reduce prediction error\n\n```\nInput:  \"The capital of France is ___\"\nTarget: \"Paris\"\n\nModel predicts â†’ Calculates loss â†’ Backpropagation â†’ Updates weights\n```\n\n### Next-Token Prediction\n\nLLMs don't \"understand\" like humans. They learn **statistical patterns**:\n\n| What LLM sees | What it learns |\n|---------------|----------------|\n| \"The sky is ___\" | \"blue\" often follows |\n| \"Once upon a ___\" | \"time\" often follows |\n| \"SELECT * FROM ___\" | Table names often follow |\n\n**Key insight**: LLMs are pattern completion machines. They predict what text *typically* follows, based on training data.\n\n### Why Hallucinations Are Expected\n\n**Hallucination** = LLM produces confident-sounding but incorrect information.\n\nThis isn't a bugâ€”it's a direct consequence of how LLMs work:\n\n| ML Concept | LLM Behavior |\n|------------|--------------|\n| Pattern completion | Generates plausible-sounding text even when facts are wrong |\n| Training data bias | Repeats errors or biases present in training data |\n| No fact-checking | Model doesn't verify claimsâ€”just predicts likely text |\n| Over-generalisation | Applies patterns to situations where they don't apply |\n\n**Example**: If asked about a fictional event, an LLM might generate a detailed, confident-sounding descriptionâ€”because that's what text about events *typically looks like*.\n\n### Why This Matters for Enterprise\n\nIn banking and enterprise settings, hallucinations are a serious risk:\n\n- **Compliance**: LLM might cite non-existent regulations\n- **Financial advice**: LLM might invent statistics or market data\n- **Legal**: LLM might fabricate case law (this has happened!)\n- **Reputation**: Incorrect information damages trust\n\n### The Solution: Grounding and RAG\n\n**RAG (Retrieval-Augmented Generation)** mitigates hallucinations by:\n\n1. **Retrieving** relevant documents from a trusted knowledge base\n2. **Providing** these documents as context to the LLM\n3. **Grounding** the response in actual evidence\n\n```\nWITHOUT RAG:\nUser question â†’ LLM â†’ Potentially hallucinated answer\n\nWITH RAG:\nUser question â†’ Search knowledge base â†’ Retrieve relevant docs \n             â†’ LLM + docs â†’ Answer grounded in evidence\n```\n\n*Think of it as giving the hiker (model) a map and signposts, rather than relying only on memory of terrain from past walks.*\n\n### Key Takeaways\n\n- LLMs are pattern completion machines, not knowledge databases\n- Hallucinations are expected behavior, not bugs\n- Training data quality directly affects output quality\n- Enterprise use requires grounding (RAG) and human oversight\n- Never trust LLM outputs for facts without verification",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "4jrvwqmgpd",
   "source": "---\n\n## Bonus: PyTorch Preview\n\nIn real ML projects, you use frameworks like **PyTorch** or **TensorFlow/Keras**.\n\nThey do the same things we did above, but:\n- Handle gradients automatically (no manual math!)\n- Run on GPUs for speed\n- Provide building blocks for complex models\n\nHere's what our training loop looks like in PyTorch:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "ccpce7tt0m",
   "source": "# PyTorch version of our training loop\n# (This is what real ML code looks like!)\n\ntry:\n    import torch\n    import torch.nn as nn\n    \n    # Training data as PyTorch tensors\n    X = torch.tensor([[1.0], [2.0], [3.0], [5.0], [7.0]])  # hours\n    y = torch.tensor([[20.0], [35.0], [50.0], [75.0], [90.0]])  # scores\n    \n    # Define a simple model (1 input â†’ 1 output)\n    model = nn.Linear(1, 1)\n    \n    # Loss function and optimizer (same concepts!)\n    loss_fn = nn.MSELoss()  # Mean Squared Error\n    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)  # Gradient Descent\n    \n    print(\"PyTorch Training Loop\")\n    print(\"=\" * 40)\n    \n    # Training loop - same 4 steps!\n    for epoch in range(100):\n        # 1. Forward pass (predict)\n        predictions = model(X)\n        \n        # 2. Calculate loss\n        loss = loss_fn(predictions, y)\n        \n        # 3. Backward pass (gradients calculated automatically!)\n        optimizer.zero_grad()\n        loss.backward()\n        \n        # 4. Update weights\n        optimizer.step()\n        \n        if epoch % 20 == 0:\n            print(f\"Epoch {epoch:3d}: loss = {loss.item():.2f}\")\n    \n    # Show learned parameters\n    weight = model.weight.item()\n    bias = model.bias.item()\n    print(f\"\\nLearned: score = {weight:.1f} Ã— hours + {bias:.1f}\")\n    \n    # Inference\n    with torch.no_grad():  # No gradients needed for inference\n        test_hours = torch.tensor([[4.0]])\n        prediction = model(test_hours)\n        print(f\"Prediction for 4 hours: {prediction.item():.0f} points\")\n\nexcept ImportError:\n    print(\"PyTorch not installed in this environment.\")\n    print(\"This is just a preview - the same concepts apply!\")\n    print()\n    print(\"Key PyTorch concepts:\")\n    print(\"  - torch.tensor() â†’ data containers\")\n    print(\"  - nn.Linear() â†’ a layer with weights\")\n    print(\"  - loss.backward() â†’ automatic gradient calculation\")\n    print(\"  - optimizer.step() â†’ update weights\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Part 11 â€” Final Summary\n\n### The Core ML Loop\n\nMachine learning works like this:\n\n1. **Start** with random guesses (weights)\n2. **Make** predictions\n3. **Measure** how wrong they are (loss)\n4. **Adjust** weights using gradients (backpropagation)\n5. **Repeat** until convergence\n\n> **Machine learning is learning by gradual improvement.**\n\n### Key Concepts Covered\n\n| Concept | What it means |\n|---------|---------------|\n| **AI â†’ ML â†’ DL â†’ LLM** | Nested hierarchy of technologies |\n| **Weights & Biases** | The learnable numbers in a model |\n| **Loss Function** | Measures how wrong predictions are |\n| **Gradient Descent** | Method to minimize loss |\n| **Backpropagation** | How errors flow backward to update weights |\n| **Convergence** | When training stabilizes (but may be local minimum) |\n| **Overfitting** | Memorizing training data instead of learning |\n| **Layers** | Input â†’ Hidden â†’ Output structure |\n| **Activation Functions** | Add non-linearity (e.g., ReLU) |\n| **Hallucinations** | LLMs generating plausible but false information |\n| **RAG** | Grounding LLM outputs with retrieved evidence |\n\n### Enterprise Implications\n\nUnderstanding these concepts helps you:\n- **Evaluate ML/AI vendors** critically\n- **Identify risks** in AI-powered systems\n- **Communicate** with technical teams\n- **Make informed decisions** about AI adoption\n- **Ensure compliance** with regulatory requirements\n\n---\n\n## End-of-Module Resources\n- [Hiker's Cheat Sheet](Module4_Hiker_CheatSheet.md) â€” Quick reference\n- [Knowledge Checks](Module4_Knowledge_Checks.md) â€” Test yourself"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}